import os
import json
import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

from decimal import Decimal
import mysql.connector


# --- åŸºæœ¬è·¯å¾‘èˆ‡ .env è¼‰å…¥ ---

ROOT_DIR = Path(__file__).resolve().parents[1]  # /srv/cockswain-core/ai-core
ENV_FILE = ROOT_DIR.parent / ".env"            # /srv/cockswain-core/.env
SNAPSHOT_DIR = ROOT_DIR / "knowledge_center" / "storage" / "datasets"


def load_env(env_path: Path) -> None:
    """
    å¾ˆå–®ç´”çš„ .env è®€å–ï¼šKEY=VALUEï¼Œå¿½ç•¥è¨»è§£èˆ‡ç©ºè¡Œã€‚
    è‹¥ç’°å¢ƒè®Šæ•¸å·²å­˜åœ¨å°±ä¸è¦†è“‹ï¼ˆä¿ç•™å¤–å±¤è¨­å®šçš„å„ªå…ˆæ¬Šï¼‰ã€‚
    """
    if not env_path.exists():
        return

    with env_path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            if "=" not in line:
                continue
            key, val = line.split("=", 1)
            key = key.strip()
            val = val.strip()
            if key and key not in os.environ:
                os.environ[key] = val


def get_db_conn():
    """
    ä¾ç…§æ¯æ©Ÿ .env é€£ç·š MySQLã€‚
    é‡é»ï¼šç¦ç”¨ SSLï¼Œèµ°æœ¬æ©Ÿ plain é€£ç·šï¼Œé¿å… do_handshake é‚£å€‹ bugã€‚
    """
    load_env(ENV_FILE)

    host = os.getenv("DB_HOST", "localhost")
    user = os.getenv("DB_USER", "cockswain_core")
    password = os.getenv("DB_PASSWORD", "")
    database = os.getenv("DB_NAME", "cockswain")
    port = int(os.getenv("DB_PORT", "3306"))

    cfg = {
        "host": host,
        "user": user,
        "password": password,
        "database": database,
        "port": port,
        # é—œéµï¼šæ˜ç¢ºè¦æ±‚ä¸è¦èµ° SSL
        "ssl_disabled": True,
    }

    return mysql.connector.connect(**cfg)


# --- JSON æ­£è¦åŒ–å·¥å…· ---

def _normalize_value(v: Any) -> Any:
    """
    æŠŠ DB æ’ˆå‡ºçš„å€¼è½‰æˆå¯ä»¥è¢« json åºåˆ—åŒ–çš„å‹åˆ¥ã€‚
    """
    if isinstance(v, (datetime.datetime, datetime.date)):
        return v.isoformat()
    if isinstance(v, Decimal):
        # è¦–æƒ…æ³å¯ä»¥æ”¹æˆ str(v)
        return float(v)
    # å…¶å®ƒå‹åˆ¥ç›´æ¥ä¸Ÿçµ¦ json è‡ªå·±è™•ç†
    return v


def _normalize_row(row: Dict[str, Any]) -> Dict[str, Any]:
    return {k: _normalize_value(v) for k, v in row.items()}


# --- å‹•æ…‹è³‡æ–™é›†çš„ DB æ“ä½œ ---

def list_datasets() -> List[Dict[str, Any]]:
    """
    åˆ—å‡ºæ‰€æœ‰å·²è¨»å†Šçš„å‹•æ…‹è³‡æ–™é›†ï¼ˆkc_dynamic_datasetsï¼‰ã€‚
    """
    conn = get_db_conn()
    try:
        cur = conn.cursor(dictionary=True)
        cur.execute(
            """
            SELECT
              id,
              dataset_code,
              name,
              description,
              source_table,
              where_clause,
              order_by_clause,
              limit_size,
              enabled,
              created_at,
              updated_at
            FROM kc_dynamic_datasets
            ORDER BY dataset_code ASC;
            """
        )
        rows = cur.fetchall()
        return rows
    finally:
        conn.close()


def get_dataset_by_code(dataset_code: str) -> Optional[Dict[str, Any]]:
    """
    ä¾ dataset_code å–å¾—å–®ä¸€å‹•æ…‹è³‡æ–™é›†å®šç¾©ã€‚
    åƒ…æŠ“ enabled=1 çš„ã€‚
    """
    conn = get_db_conn()
    try:
        cur = conn.cursor(dictionary=True)
        cur.execute(
            """
            SELECT
              id,
              dataset_code,
              name,
              description,
              source_table,
              where_clause,
              order_by_clause,
              limit_size,
              enabled,
              created_at,
              updated_at
            FROM kc_dynamic_datasets
            WHERE dataset_code = %s
              AND enabled = 1
            LIMIT 1;
            """,
            (dataset_code,),
        )
        row = cur.fetchone()
        return row
    finally:
        conn.close()


def query_dataset_rows(ds: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    æ ¹æ“š kc_dynamic_datasets çš„è¨­å®šå»æŸ¥å¯¦éš›è³‡æ–™è¡¨ï¼Œè¼¸å‡º rowsï¼ˆlist of dictï¼‰ã€‚
    ç›®å‰å…ˆæ”¯æ´ï¼š
      - å–®ä¸€ source_table
      - WHERE / ORDER BY / LIMIT éƒ½ç”± ds æ±ºå®š
    """
    source_table = ds["source_table"]
    where_clause = ds.get("where_clause") or ""
    order_by_clause = ds.get("order_by_clause") or ""
    limit_size = ds.get("limit_size") or 1000

    # åŸºæœ¬ SELECT *
    sql = f"SELECT * FROM {source_table}"
    params: list[Any] = []

    if where_clause.strip():
        sql += f" WHERE {where_clause}"

    if order_by_clause.strip():
        sql += f" ORDER BY {order_by_clause}"

    # æœ€å¾ŒåŠ ä¸Š LIMITï¼Œé¿å…ç‚¸å‡ºéå¤šè³‡æ–™
    sql += " LIMIT %s"
    params.append(int(limit_size))

    conn = get_db_conn()
    try:
        cur = conn.cursor(dictionary=True)
        cur.execute(sql, params)
        rows = cur.fetchall()
        return rows
    finally:
        conn.close()


def build_dataset_snapshot(dataset_code: str) -> Path:
    """
    é‡å°æŒ‡å®š dataset_code å»ºç«‹ä¸€æ¬¡ã€Œå¿«ç…§æª”ã€ï¼š
      - æœƒè®€ kc_dynamic_datasets çš„è¨­å®š
      - æŸ¥è©¢ source_table çš„å¯¦éš›è³‡æ–™
      - å­˜æˆ JSON æª”æ¡ˆï¼ˆå« metaï¼‰
    æª”åæ ¼å¼ï¼š
      storage/datasets/{dataset_code}_{YYYYmmdd_HHMMSS}.json
    """
    ds = get_dataset_by_code(dataset_code)
    if not ds:
        raise RuntimeError(f"dataset_code='{dataset_code}' ä¸å­˜åœ¨æˆ–æœªå•Ÿç”¨ (enabled=1)ã€‚")

    rows = query_dataset_rows(ds)
    # ğŸ”‘ æŠŠæ¯ä¸€ row åš JSON æ­£è¦åŒ–
    norm_rows = [_normalize_row(r) for r in rows]

    SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)

    now = datetime.datetime.now()
    ts_str = now.strftime("%Y%m%d_%H%M%S")
    out_file = SNAPSHOT_DIR / f"{dataset_code}_{ts_str}.json"

    payload = {
        "meta": {
            "dataset_code": ds["dataset_code"],
            "name": ds["name"],
            "description": ds.get("description"),
            "source_table": ds["source_table"],
            "generated_at": now.isoformat(),
            "row_count": len(norm_rows),
        },
        "rows": norm_rows,
    }

    with out_file.open("w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)

    return out_file


# --- CLI å…¥å£ ---

def cli_list() -> None:
    rows = list_datasets()
    if not rows:
        print("[datasets] ç›®å‰æ²’æœ‰ä»»ä½•å‹•æ…‹è³‡æ–™é›†å®šç¾©ï¼ˆkc_dynamic_datasets ç‚ºç©ºï¼‰ã€‚")
        return

    print("[datasets] å‹•æ…‹è³‡æ–™é›†åˆ—è¡¨ï¼š")
    for ds in rows:
        status = "ENABLED" if ds["enabled"] else "DISABLED"
        print(f"- {ds['dataset_code']} [{status}]")
        print(f"    name    : {ds['name']}")
        if ds.get("description"):
            print(f"    desc    : {ds['description']}")
        print(f"    table   : {ds['source_table']}")
        if ds.get("where_clause"):
            print(f"    where   : {ds['where_clause']}")
        if ds.get("order_by_clause"):
            print(f"    order by: {ds['order_by_clause']}")
        print(f"    limit   : {ds.get('limit_size')}")
        print("")


def cli_build(dataset_code: str) -> None:
    out_file = build_dataset_snapshot(dataset_code)
    print(f"[datasets] dataset={dataset_code} snapshot å»ºç«‹å®Œæˆï¼š{out_file}")


def main():
    import sys

    if len(sys.argv) < 2:
        print("ç”¨æ³•ï¼š")
        print("  python -m knowledge_center.dynamic_sets list")
        print("  python -m knowledge_center.dynamic_sets build <dataset_code>")
        raise SystemExit(1)

    cmd = sys.argv[1]

    if cmd == "list":
        cli_list()
    elif cmd == "build":
        if len(sys.argv) < 3:
            print("ç¼ºå°‘ dataset_code")
            raise SystemExit(1)
        dataset_code = sys.argv[2]
        cli_build(dataset_code)
    else:
        print(f"æœªçŸ¥æŒ‡ä»¤ï¼š{cmd}")
        raise SystemExit(1)


if __name__ == "__main__":
    main()
